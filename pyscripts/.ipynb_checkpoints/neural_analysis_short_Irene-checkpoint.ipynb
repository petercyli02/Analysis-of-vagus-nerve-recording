{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e961d4d",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Load-data\" data-toc-modified-id=\"Load-data-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Load data</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a5bfd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython\n",
    "# IPython.Application.instance().kernel.do_shutdown(True)\n",
    "\n",
    "# %matplotlib notebook \n",
    "#import mpld3\n",
    "#mpld3.enable_notebook()\n",
    "\n",
    "%matplotlib widget\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import time\n",
    "import datetime\n",
    "import pycwt\n",
    "import statistics\n",
    "import random\n",
    "import pickle\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import sklearn as sk\n",
    "import tkinter as tk\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "from sklearn import decomposition\n",
    "from sklearn.decomposition import PCA\n",
    "from tkinter import *\n",
    "from tkinter import ttk\n",
    "from sklearn import preprocessing\n",
    "from datetime import date\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "from neurodsp.rhythm import sliding_window_matching\n",
    "from neurodsp.utils.download import load_ndsp_data\n",
    "from neurodsp.plts.rhythm import plot_swm_pattern\n",
    "from neurodsp.plts.time_series import plot_time_series\n",
    "from neurodsp.utils import set_random_seed, create_times\n",
    "# Import listed chormap\n",
    "from matplotlib.colors import ListedColormap\n",
    "import matplotlib.dates as md\n",
    "from matplotlib import colors as mcolors\n",
    "# Scipy\n",
    "from scipy import signal\n",
    "from scipy import ndimage\n",
    "# TKinter for selecting files\n",
    "from tkinter import Tk     # from tkinter import Tk for Python 3.x\n",
    "from tkinter.filedialog import askdirectory\n",
    "\n",
    "# Add my module to python path\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "# Own libraries\n",
    "from Neurogram_short import * # Recording, MyWavelet, MyWaveforms\n",
    "\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9676d777",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45341f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "Tk().withdraw()  # keep the root window from appearing\n",
    "dir_name = ('../datasets/')\n",
    "path = '../datasets' # Port B\n",
    "\n",
    "map_path = '../datasets/cambridge/recording/forearm/forearm_map.csv'\n",
    "\n",
    "# When using port A: channels=range(0,32,1) by default port B:range(32,64,1)\n",
    "# Start and dur in samples\n",
    "# feinstein: channels=[0]\n",
    "time_start = time.time()\n",
    "load_from_file=True\n",
    "downsample = 3             #Only when loading from raw   \n",
    "start= 0                    # SC chronic: 7*30000              #2*60*10000 # 0*30000 ## start=2*60*10000\n",
    "dur= None                # SC chronic: 4*30000           # EMG: 35*30000\n",
    "port = 'Port B'\n",
    "record = Recording.open_record(path, start=start, dur=dur, \n",
    "                               load_from_file=load_from_file, \n",
    "                               load_multiple_files=True,\n",
    "                               downsample=downsample,\n",
    "                               port=port  ,  # Select recording port\n",
    "                               map_path=map_path,\n",
    "                               verbose=0)\n",
    "\n",
    "# Create directory to save figures\n",
    "if not os.path.exists('%s/figures/' %(path)):\n",
    "    os.makedirs('%s/figures/' %(path))\n",
    "print(\"Time elapsed: {} seconds\".format(time.time()-time_start)) \n",
    "\n",
    "#sys.exit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b83fdbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get current time for saving (avoid overwriting)\n",
    "now = datetime.datetime.now()\n",
    "current_time = now.strftime(\"%d%m%Y_%H%M%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2fd79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0f3074",
   "metadata": {},
   "outputs": [],
   "source": [
    "options_filter = [\n",
    "    \"None\", \n",
    "    \"butter\", \n",
    "    \"fir\"]                # Binomial Weighted Average Filter\n",
    "\n",
    "options_detection = [\n",
    "    \"get_spikes_threshCrossing\", # Ojo: get_spikes_threshCrossing needs detects also cardiac \n",
    "                                     # spikes, so use cardiac_window. This method is slower\n",
    "    \"get_spikes_method\",         # Python implemented get_spikes() method. Faster\n",
    "    \"so_cfar\"]                    # Smallest of constant false-alarm rate filter\n",
    "\n",
    "options_threshold = [\n",
    "    \"positive\",\n",
    "    \"negative\", \n",
    "    \"both_thresh\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca88e845",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure\n",
    "config_text = []\n",
    "record.apply_filter = options_filter[1]    \n",
    "record.detect_method = options_detection[1]                                    \n",
    "record.thresh_type = options_threshold[0]\n",
    "# Select channel position/number in intan (not channel number in device)\n",
    "\n",
    "record.channels = [2,4]  # Pairs 2&4, 27&30\n",
    "record.path = path  \n",
    "config_text = ['Load_from_file %s' %load_from_file, 'Filter: %s'%record.apply_filter, 'Detection: %s'%record.detect_method, 'Threhold type: %s'%record.thresh_type, 'Channels: %s' %record.channels, 'Downsampling: %s' %downsample]\n",
    "config_text.append('Port %s' %(port))\n",
    "config_text.append('Start %s, Dur: %s' %(start,dur))\n",
    "config_text.append('Channels: %s' %record.channels)\n",
    "# Ramarkable timestamps (in sec) \n",
    "\n",
    "group = '1'\n",
    "\n",
    "print('SELECTED GENERAL CONFIGURATION:')\n",
    "print('Filter: %s'%record.apply_filter)\n",
    "print('Detection: %s'%record.detect_method)\n",
    "print('Threhold type: %s'%record.thresh_type)\n",
    "print('Channels: %s' %record.channels) \n",
    "print('-------------------------------------')\n",
    "\n",
    "record.select_channels(record.channels) # keep_ch_loc=True if we want to display following the map. Otherwise follow the order provided by selected channels.\n",
    "print('map_array: %s' %record.map_array)\n",
    "print('ch_loc: %s' %record.ch_loc)\n",
    "print('filter_ch %s' %record.filter_ch)\n",
    "print('column_ch %s' %record.column_ch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "042e12d7",
   "metadata": {},
   "source": [
    "#### Select visualization options:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826db0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure\n",
    "record.num_rows = 2#int(round(len(record.filter_ch)/2)) # round(n_components/2) \n",
    "record.num_columns = 1#int(len(record.filter_ch)-round(len(record.filter_ch)/2))+1 \n",
    "plot_ch = int(record.map_array[record.ch_loc[0]])                \n",
    "print(plot_ch)\n",
    "print(record.num_rows)\n",
    "print(record.num_columns)\n",
    "save_figure = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f434ecb2",
   "metadata": {},
   "source": [
    "##### Gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a6d286",
   "metadata": {},
   "outputs": [],
   "source": [
    "gain = 1\n",
    "config_text.append('Gain: %s' %(gain))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a1b0a1",
   "metadata": {},
   "source": [
    "##### Maximum bpm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb453a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "bpm = 300\n",
    "record.set_bpm(bpm) # General max bpm in rat HR. Current neurograms at 180bpm\n",
    "config_text.append('BPM: %s' %(bpm))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4818cec1",
   "metadata": {},
   "source": [
    "##### Spike detection config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7176b602",
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_detection_config = {\n",
    "    'general':{\n",
    "        'cardiac': False,\n",
    "        # Length of window that containes a neural spike\n",
    "        'spike_window': [int(0.002 * record.fs), int(0.002 * record.fs)], #[int(0.002 * record.fs), int(0.002 * record.fs)],   #[int(0.0018 * record.fs), int(0.0018 * record.fs)],  # in total 0.36s length AP: 3ms to refractory and 5ms total\n",
    "        'min_thr': [0, 200],              # Min & max of amplitude of identified spikes\n",
    "        'half_width': [0.1/1000,10/1000],  # Length in sec from zero cross to max of waveform. 0.5/1000\n",
    "        'C': 3,  #3\n",
    "        'find_peaks_args': {\n",
    "        # Input to find_peaks() function:\n",
    "        # Required minimal horizontal distance (>= 1) in samples between \n",
    "        # neighbouring peaks. Smaller peaks are removed first until the \n",
    "        # condition is fulfilled for all remaining peaks.\n",
    "        'distance': int(0.0018 * 2 * record.fs),\n",
    "        }\n",
    "    },\n",
    "    'cfar':{\n",
    "        # Parameters for cfar only\n",
    "        'nstd_cfar': 3,  \n",
    "        'wdur': 1501 / record.fs,   # SO-CFAR window duration in seconds   1501      5001\n",
    "        'gdur': 10 / record.fs,     # SO-CFAR guard duration in seconds   10         50\n",
    "    }\n",
    "}\n",
    "\n",
    "hr_detection_config = {\n",
    "    'general':{\n",
    "    'cardiac': True,\n",
    "    # Minimum separation between beats: samples between beats minus a buffer of 0.01s\n",
    "    'window' : int(record.fs / (record.bpm / 60)-(0.01*record.fs)), #  3beats/second int(0.08 / 2 * record.fs) #1500    500 2500\n",
    "    # Samples around a HR where a neural spike will be discarded (HR peak may deform signal)\n",
    "    'spike_window': [int(0.03*record.fs), int(0.03*record.fs)], \n",
    "    'min_thr': [0, 0],              # Not used\n",
    "    'half_width': [0,0],  # Not used \n",
    "    'C': 2,\n",
    "    'find_peaks_args': {\n",
    "        # Input to find_peaks() function:\n",
    "        # Required minimal horizontal distance (>= 1) in samples between \n",
    "        # neighbouring peaks. Smaller peaks are removed first until the \n",
    "        # condition is fulfilled for all remaining peaks.\n",
    "        'distance': int(record.fs / (record.bpm / 60)-(0.01*record.fs)) #0.0018 * 2 * record.fs  # 0.23s  3beats/second\n",
    "    }\n",
    "    }\n",
    "}\n",
    "\n",
    "noise_detection_config = {\n",
    "    'general':{\n",
    "    'cardiac': False,\n",
    "    # Minimum separation between artifacts: samples between beats minus a buffer of 0.05s\n",
    "    'window' : 10,\n",
    "    # Samples around an artifact where a neural spike will be discarded (artifact peak may deform signal)\n",
    "    'spike_window': [int(0.1*record.fs), int(0.1*record.fs)],  #0.01\n",
    "    'C': 20, #20\n",
    "    'find_peaks_args': {\n",
    "        # Input to find_peaks() function:\n",
    "        # Required minimal horizontal distance (>= 1) in samples between \n",
    "        # neighbouring peaks. Smaller peaks are removed first until the \n",
    "        # condition is fulfilled for all remaining peaks.\n",
    "        'distance': 10\n",
    "    }\n",
    "    }\n",
    "}\n",
    "\n",
    "config_text.append('spike_detection_config: %s  ||  hr_detection_config: %s ||  noise_detection_config: %s ' %(json.dumps(spike_detection_config), json.dumps(hr_detection_config), json.dumps(noise_detection_config)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d379fd51",
   "metadata": {},
   "source": [
    "#### Final initializations (No need to change)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6576596f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize dataframe for results \n",
    "#----------------------------------------------------\n",
    "record.rolling_metrics = pd.DataFrame()\n",
    "record.summary = pd.DataFrame(columns=['Max_spike_rate', 'Min_spike_rate',\n",
    "                                'Max_amplitude_sum', 'Min_amplitude_sum'])\n",
    "record.summary.index.name = 'channel'\n",
    "record.sig2noise = [] #To save the snr for each channel\n",
    "\n",
    "# Intialize dataframes for wavelet decomposition\n",
    "#----------------------------------------------------\n",
    "neural_wvl = pd.DataFrame(columns=record.filter_ch)\n",
    "neural_wvl_denoised = pd.DataFrame(columns=record.filter_ch)\n",
    "other_wvl = pd.DataFrame(columns=record.filter_ch)\n",
    "substraction_wvl = pd.DataFrame(columns=record.filter_ch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d89c097e",
   "metadata": {},
   "source": [
    "### Plot raw signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f540de14",
   "metadata": {},
   "outputs": [],
   "source": [
    "record.plot_freq_content(record.original,int(plot_ch), nperseg=512, max_freq=4000, ylim=[-500, 500], dtformat='%H:%M:%S',\n",
    "                         figsize=(10, 10), savefigpath='%s/figures/%s_ch%s_original-%s.png' %(record.path, port, plot_ch, current_time), \n",
    "                         show=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c913fe",
   "metadata": {},
   "source": [
    "### Channel referencing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469b10b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "radial_chanels = ['ch_1', 'ch_2', 'ch_3', 'ch_4', 'ch_26', 'ch_27', 'ch_28', 'ch_29', 'ch_30','ch_31']\n",
    "\n",
    "channels =  radial_chanels  #record.filter_ch\n",
    "ref_ch_name = 'mean' #'mean'\n",
    "if ref_ch_name == 'mean':\n",
    "    all_ch_list = [col for col in channels if col.startswith('ch_')] \n",
    "    ref_ch = record.original[all_ch_list].mean(axis=1)\n",
    "else:\n",
    "    ref_ch = record.original['ch_%s'%ref_ch_name]  \n",
    "record.referenced = record.original[record.filter_ch].sub(ref_ch, axis=0)\n",
    "record.referenced['seconds'] = record.original['seconds']\n",
    "record.recording=record.referenced\n",
    "record.recording.name = 'referenced'\n",
    "config_text.append('ref_ch: %s' % ref_ch_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6884128",
   "metadata": {},
   "outputs": [],
   "source": [
    "record.plot_freq_content(record.referenced,int(plot_ch), nperseg=512, max_freq=4000, ylim=[-750,750], dtformat='%H:%M:%S',figsize=(10, 10),\n",
    "                         savefigpath='%s/figures/%s_ch%s_ref%s-%s.png' %(record.path, port, plot_ch, ref_ch_name, current_time),\n",
    "                         show=True) \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c10eaa6",
   "metadata": {},
   "source": [
    "### Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f5c95f8",
   "metadata": {},
   "source": [
    "#### Bandwidth filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1bcd3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure\n",
    "filt_config = {\n",
    "    'W': [400, 2000],  # (max needs to be <fs/2 per Nyquist)\n",
    "    'None': {},\n",
    "    'butter': {\n",
    "            'N': 4,                # The order of the filter\n",
    "            'btype': 'bandpass', #'bandpass', #'hp'  #'lowpass'     # The type of filter.\n",
    "    },      \n",
    "    'fir': {\n",
    "            'n': 4,\n",
    "    },\n",
    "    'notch': {\n",
    "            'quality_factor': 30,\n",
    "    },\n",
    "}\n",
    "\n",
    "filt_config['butter']['Wn'] = filt_config['W']\n",
    "filt_config['butter']['fs'] = record.fs\n",
    "\n",
    "config_text.append('filt_config: %s' %json.dumps(filt_config))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d91ed6",
   "metadata": {},
   "source": [
    "##### Apply filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0965a10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure\n",
    "time_start = time.time()\n",
    "signal2filter = record.recording\n",
    "config_text.append('signal2filter: %s' %signal2filter.name)\n",
    "record.filter(signal2filter, record.apply_filter, **filt_config[record.apply_filter])\n",
    "# Change from float64 to float 16\n",
    "record.filtered = convertDfType(record.filtered, typeFloat='float32')\n",
    "#print(record.filtered.dtypes)\n",
    "print(\"Time elapsed: {} seconds\".format(time.time()-time_start))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a8418f4",
   "metadata": {},
   "source": [
    "##### Plot filtered signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d19f5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_label = 'Filtered'\n",
    "text = 'Channels after %s filtering'%record.apply_filter\n",
    "record.plot_freq_content(record.filtered,int(plot_ch), nperseg=512, max_freq=4000, ylim=[-100, 100], dtformat='%H:%M:%S',\n",
    "                         figsize=(10, 10), savefigpath='%s/figures/%s_ch%s_butter_filtering-%s.png' %(record.path,port,plot_ch, current_time),"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3598d277",
   "metadata": {},
   "source": [
    "#### Notch filtering"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e005bc72",
   "metadata": {},
   "source": [
    "time_start = time.time()\n",
    "freq_notch =  range(450, 2000, 100) #range(50, 400, 100) #2000 [1650] #[350, 450, 550, 1550] range(450, 4000, 100)\n",
    "for n in freq_notch:\n",
    "    filt_config['notch']['notch_freq'] = n\n",
    "    record.filter(record.filtered, 'notch', **filt_config['notch'])\n",
    "print(\"Time elapsed: {} seconds\".format(time.time()-time_start))\n",
    "config_text.append('notch_filtered:applied')\n",
    "# Change from float64 to float 16\n",
    "record.filtered = convertDfType(record.filtered, typeFloat='float32')\n",
    "\n",
    "record.recording=record.filtered\n",
    "record.recording.name = 'filtered'"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4790cd19",
   "metadata": {},
   "source": [
    "text_label = 'Filtered'\n",
    "text = 'Channels after %s filtering'%'notch'\n",
    "\n",
    "record.plot_freq_content(record.filtered, int(plot_ch), ylim=[-100, 100], nperseg=512, max_freq=4000, dtformat='%H:%M:%S',\n",
    "                         figsize=(10, 10), savefigpath='%s/figures/%s_ch%s_allfilt-%s.png' %(record.path, port,plot_ch, current_time), show=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca8f5570",
   "metadata": {},
   "source": [
    "### NOISE: Envelope derivative operator (EDO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3608d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_edo=pd.DataFrame()\n",
    "\n",
    "for ch in record.filter_ch:\n",
    "    x = record.recording[ch].to_numpy() \n",
    "    # Apply EDO filter\n",
    "    x_e = gen_edo(x)\n",
    "    # Store in DF to be loaded in signal analysis\n",
    "    noise_edo[ch] = x_e\n",
    "noise_edo['seconds'] = np.asarray(record.recording['seconds'])\n",
    "noise_edo.index = pd.DatetimeIndex(noise_edo.seconds * 1e9)\n",
    "noise_edo.index.name = 'time'\n",
    "noise_edo.name = 'noise_edo'\n",
    "\n",
    "config_text.append('signal to EDO: %s' %record.recording.name)\n",
    "\n",
    "# Change from float64 to float 32\n",
    "#noise_edo = convertDfType(noise_edo, typeFloat='float32')\n",
    "#print(noise_edo.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d28c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "record.plot_freq_content(noise_edo, int(plot_ch), nperseg=512, max_freq=4000, dtformat='%H:%M:%S.%f',\n",
    "                         figsize=(10, 10), show=False) \n",
    "\n",
    "if save_figure:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac21932a",
   "metadata": {},
   "source": [
    "## Signal analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d39974",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure\n",
    "\n",
    "# Select the signal that will be used to extract the neural spikes from\n",
    "record.signal2analyse = record.recording     # record.filtered #neural_wvl #substraction_wvl #record.recording # record.recording #neural_wvl_denoised\n",
    "record.signal2extract = record.signal2analyse  #record.filtered #substraction_wvl #record.recording #record.recording #neural_wvl_denoised #record.recording\n",
    "print('Analysing signal: %s' %record.signal2analyse.name)\n",
    "\n",
    "noise_signal = noise_edo\n",
    "\n",
    "config_text.append('signal2analyse: %s' %record.signal2analyse.name)\n",
    "config_text.append('signal2extract: %s' %record.signal2extract.name)\n",
    "try:\n",
    "    config_text.append('noise_signal: %s '%noise_signal.name)\n",
    "    print(noise_signal.name)\n",
    "except:\n",
    "    config_text.append('noise_signal: %s' %'None') #'noise_edo' 'other_wvl_denoised'\n",
    "\n",
    "cardiac_noise_config = False  # vs other noise configuration\n",
    "consider_noise = True\n",
    "\n",
    "#record.manual_thres = [10, -10] \n",
    "\n",
    "dtformat = '%M:%S.%f' #'%H:%M:%S'\n",
    "\n",
    "verbose = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f7f4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------------------------------------\n",
    "# Initialize figures\n",
    "#-------------------------------------------------------------\n",
    "time_start_analysis=time.time()\n",
    "\n",
    "fig, axes = plt.subplots(record.num_rows, record.num_columns, figsize=(15, 5), sharex=True)\n",
    "fig.suptitle('Identified peaks', fontsize=16, family='serif')\n",
    "\n",
    "fig4, axes_metric = plt.subplots(2,1,figsize=(12, 10))\n",
    "fig4.suptitle('Metrics evolution', fontsize=16, family='serif')\n",
    "\n",
    "if (record.num_rows*record.num_columns)>1:\n",
    "    fig2, axes_wv = plt.subplots(record.num_rows, record.num_columns, figsize=(15, 8), sharex=True)\n",
    "    fig2.suptitle('Waveforms', fontsize=16, family='serif')  \n",
    "    axes = axes.flatten()\n",
    "    axes_wv = axes_wv.flatten()\n",
    "\n",
    "if cardiac_noise_config:\n",
    "    other_detection_config = hr_detection_config\n",
    "else:\n",
    "    other_detection_config = noise_detection_config    \n",
    "\n",
    "save_waveforms = []\n",
    "for n, j in enumerate(record.ch_loc): \n",
    "    \n",
    "    if verbose:\n",
    "        print(n)\n",
    "        print(j)\n",
    "        \n",
    "    try:\n",
    "        if record.signal2analyse.name=='ica':\n",
    "            ch = 'ch_ica'\n",
    "        else:\n",
    "            ch = 'ch_%s'%int(record.map_array[j])\n",
    "        \n",
    "        if len(noise_signal)>0:\n",
    "            noise = noise_signal[ch]\n",
    "        else:\n",
    "            noise = []   \n",
    "        print(ch)\n",
    "        \n",
    "        #-------------------------------------------------------------\n",
    "        # Start pipeline of cardiac and neural peaks identification\n",
    "        #-------------------------------------------------------------\n",
    "        hr_idx, hr_vector, spikes_idx, waves, spikes_vector, spikes_vector_loc, index_first_edge = \\\n",
    "                                record.pipeline_peak_extraction(ch, noise_signal, other_detection_config, \n",
    "                                                                spike_detection_config,\n",
    "                                                                consider_noise=consider_noise, verbose=True)\n",
    "        # Create waveform object for processing of waveforms\n",
    "        waveforms = MyWaveforms(waves, record.signal2extract, record.fs, spikes_vector_loc, num_clus, record.path)\n",
    "\n",
    "        #-------------------------------------------------------------\n",
    "        # Compute overall rolling metrics \n",
    "        #-------------------------------------------------------------\n",
    "        # If not enough spikes\n",
    "        if len(spikes_idx) < 5:\n",
    "            try: \n",
    "                record.rolling_metrics['%s' %ch] = np.nan\n",
    "            except TypeError:\n",
    "                print('%s was not processed and will not appear in rolling_metrics dataframe' %ch)    \n",
    "            continue\n",
    "        else:\n",
    "            record.recording['spikes_amplitudes_%s' %ch] = spikes_vector\n",
    "            record.recording['spikes_locations_%s' %ch] = spikes_vector_loc\n",
    "            record.rolling_metrics['%s' %ch] = record.compute_rolling_metrics(record.signal2analyse,axes_metric, ch, \n",
    "                                                                              window=10, units='s', dtformat=dtformat, \n",
    "                                                                              show_plot=True, time_marks=time_marks)   # Returns only [metric_spikes_rate_%s' %ch]\n",
    "\n",
    "    except KeyError:\n",
    "        print('channel %s not found' %int(record.map_array[j]))\n",
    "\n",
    "print ('Analysis done! Time elapsed: {} seconds'.format(time.time()-time_start_analysis))\n",
    "\n",
    "if save_figure:\n",
    "    fig4.savefig('%s/figures/metrics_evolution-%s_%s_group%s.svg' %(path, current_time, run, group), facecolor='w')\n",
    "\n",
    "sys.exit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
